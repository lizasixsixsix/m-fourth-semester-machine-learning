{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mo-2-4-0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJbO6Hqtaukq",
        "colab_type": "text"
      },
      "source": [
        "# Лабораторная работа №4\n",
        "\n",
        "## Реализация приложения по распознаванию номеров домов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jBSK2FabPKC",
        "colab_type": "text"
      },
      "source": [
        "Набор изображений из _Google Street View_ с изображениями номеров домов, содержащий 10 классов, соответствующих цифрам от 0 до 9.\n",
        "\n",
        "* 73257 изображений цифр в обучающей выборке;\n",
        "\n",
        "* 26032 изображения цифр в тестовой выборке;\n",
        "\n",
        "* 531131 изображения, которые можно использовать как дополнение к обучающей выборке;\n",
        "\n",
        "* В двух форматах:\n",
        "\n",
        "    * Оригинальные изображения с выделенными цифрами;\n",
        "\n",
        "    * Изображения размером 32×32, содержащие одну цифру;\n",
        "\n",
        "* Данные первого формата можно скачать по ссылкам:\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/train.tar.gz (обучающая выборка);\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/test.tar.gz (тестовая выборка);\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/extra.tar.gz (дополнительные данные);\n",
        "\n",
        "* Данные второго формата можно скачать по ссылкам:\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/train_32x32.mat (обучающая выборка);\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/test_32x32.mat (тестовая выборка);\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/extra_32x32.mat (дополнительные данные);\n",
        "\n",
        "* Описание данных на английском языке доступно по ссылке:\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8r0rcrSbum0",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Реализуйте глубокую нейронную сеть (полносвязную или сверточную) и обучите ее на синтетических данных (например, наборы _MNIST_ (http://yann.lecun.com/exdb/mnist/) или _notMNIST_).\n",
        "\n",
        "Ознакомьтесь с имеющимися работами по данной тематике: англоязычная статья ( http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf ), видео на _YouTube_ (https://www.youtube.com/watch?v=vGPI_JvLoN0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5VyFAn6oppw",
        "colab_type": "code",
        "outputId": "bf5cee09-dfc3-4e70-a8de-66ce637a6532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "! pip install tensorflow-gpu --pre --quiet\n",
        "\n",
        "! pip show tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow-gpu\n",
            "Version: 2.2.0rc2\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tensorboard, grpcio, protobuf, keras-preprocessing, tensorflow-estimator, google-pasta, six, wheel, absl-py, numpy, astunparse, scipy, termcolor, wrapt, h5py, gast, opt-einsum\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A6ova40mePh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxMOj2NcyUrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqe79JL0mGNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEaLeEAKy-sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val = tf.keras.utils.normalize(x_train, axis = 1), tf.keras.utils.normalize(x_val, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDy2wUQwyQFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val = x_train[..., np.newaxis], x_val[..., np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA-LEJ-DH85n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52752c77-02f4-4800-9a8b-b4dbc254e962"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train, y_val = to_categorical(y_train), to_categorical(y_val)\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW4-m2kcv1bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_DIM_0, IMAGE_DIM_1 = x_train.shape[1], x_train.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8FxR1mymxWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES_N = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfSn_LKOm6U_",
        "colab_type": "code",
        "outputId": "2762bbde-63b3-45d2-a71d-08e5ed360ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape, x_val.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGJQ6uXanJQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Flatten\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(6, kernel_size = (5, 5), strides = (1, 1), activation = 'tanh', padding = 'same',\n",
        "                   input_shape = (IMAGE_DIM_0, IMAGE_DIM_1, 1)))\n",
        "model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model.add(Conv2D(16, kernel_size = (5, 5), strides = (1, 1), activation = 'tanh', padding = 'valid'))\n",
        "model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120, activation = 'tanh'))\n",
        "model.add(Dense(84, activation = 'tanh'))\n",
        "model.add(Dense(CLASSES_N, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF5wW8VYnca7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'sparse_categorical_crossentropy' gave NAN loss\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiqd4HCfnezG",
        "colab_type": "code",
        "outputId": "9c1c5d02-5dfe-431c-ebba-b6071db22104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnv6sb5Tniww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS_N = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWfwaspGnsVK",
        "colab_type": "code",
        "outputId": "4c48bf17-e5b0-42bd-fd93-ff41e0a17893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_data=(x_val, y_val), epochs = EPOCHS_N)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2555 - categorical_accuracy: 0.9240 - val_loss: 0.1317 - val_categorical_accuracy: 0.9600\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1088 - categorical_accuracy: 0.9669 - val_loss: 0.0921 - val_categorical_accuracy: 0.9732\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0755 - categorical_accuracy: 0.9765 - val_loss: 0.0822 - val_categorical_accuracy: 0.9734\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0579 - categorical_accuracy: 0.9820 - val_loss: 0.0723 - val_categorical_accuracy: 0.9771\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0468 - categorical_accuracy: 0.9858 - val_loss: 0.0619 - val_categorical_accuracy: 0.9817\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0390 - categorical_accuracy: 0.9876 - val_loss: 0.0673 - val_categorical_accuracy: 0.9785\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0321 - categorical_accuracy: 0.9895 - val_loss: 0.0639 - val_categorical_accuracy: 0.9812\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0282 - categorical_accuracy: 0.9908 - val_loss: 0.0618 - val_categorical_accuracy: 0.9821\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0239 - categorical_accuracy: 0.9922 - val_loss: 0.0611 - val_categorical_accuracy: 0.9825\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0199 - categorical_accuracy: 0.9933 - val_loss: 0.0604 - val_categorical_accuracy: 0.9823\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0199 - categorical_accuracy: 0.9933 - val_loss: 0.0628 - val_categorical_accuracy: 0.9827\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0155 - categorical_accuracy: 0.9947 - val_loss: 0.0624 - val_categorical_accuracy: 0.9820\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0151 - categorical_accuracy: 0.9948 - val_loss: 0.0663 - val_categorical_accuracy: 0.9835\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0142 - categorical_accuracy: 0.9953 - val_loss: 0.0648 - val_categorical_accuracy: 0.9831\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0133 - categorical_accuracy: 0.9958 - val_loss: 0.0643 - val_categorical_accuracy: 0.9839\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0112 - categorical_accuracy: 0.9962 - val_loss: 0.0647 - val_categorical_accuracy: 0.9841\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0098 - categorical_accuracy: 0.9971 - val_loss: 0.0703 - val_categorical_accuracy: 0.9826\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0099 - categorical_accuracy: 0.9966 - val_loss: 0.0728 - val_categorical_accuracy: 0.9834\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0092 - categorical_accuracy: 0.9967 - val_loss: 0.0760 - val_categorical_accuracy: 0.9826\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0081 - categorical_accuracy: 0.9973 - val_loss: 0.0718 - val_categorical_accuracy: 0.9836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4960036748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhEJUbH-b9RT",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "После уточнения модели на синтетических данных попробуйте обучить ее на реальных данных (набор _Google Street View_). Что изменилось в модели?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI_e3nVUcCXb",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3\n",
        "\n",
        "Сделайте множество снимков изображений номеров домов с помощью смартфона на ОС _Android_. Также можно использовать библиотеки _OpenCV_, _Simple CV_ или _Pygame_ для обработки изображений с общедоступных камер видеонаблюдения (например, https://www.earthcam.com/).\n",
        "\n",
        "В качестве примера использования библиотеки _TensorFlow_ на смартфоне можете воспользоваться демонстрационным приложением от _Google_ (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDRp62kQcQd8",
        "colab_type": "text"
      },
      "source": [
        "### Задание 4\n",
        "\n",
        "Реализуйте приложение для ОС _Android_, которое может распознавать цифры в номерах домов, используя разработанный ранее классификатор. Какова доля правильных классификаций?"
      ]
    }
  ]
}