{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mo-2-4-0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJbO6Hqtaukq",
        "colab_type": "text"
      },
      "source": [
        "# Лабораторная работа №4\n",
        "\n",
        "## Реализация приложения по распознаванию номеров домов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jBSK2FabPKC",
        "colab_type": "text"
      },
      "source": [
        "Набор изображений из _Google Street View_ с изображениями номеров домов, содержащий 10 классов, соответствующих цифрам от 0 до 9.\n",
        "\n",
        "* 73257 изображений цифр в обучающей выборке;\n",
        "\n",
        "* 26032 изображения цифр в тестовой выборке;\n",
        "\n",
        "* 531131 изображения, которые можно использовать как дополнение к обучающей выборке;\n",
        "\n",
        "* В двух форматах:\n",
        "\n",
        "    * Оригинальные изображения с выделенными цифрами;\n",
        "\n",
        "    * Изображения размером 32×32, содержащие одну цифру;\n",
        "\n",
        "* Данные первого формата можно скачать по ссылкам:\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/train.tar.gz (обучающая выборка);\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/test.tar.gz (тестовая выборка);\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/extra.tar.gz (дополнительные данные);\n",
        "\n",
        "* Данные второго формата можно скачать по ссылкам:\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/train_32x32.mat (обучающая выборка);\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/test_32x32.mat (тестовая выборка);\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/extra_32x32.mat (дополнительные данные);\n",
        "\n",
        "* Описание данных на английском языке доступно по ссылке:\n",
        "\n",
        "    * http://ufldl.stanford.edu/housenumbers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8r0rcrSbum0",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Реализуйте глубокую нейронную сеть (полносвязную или сверточную) и обучите ее на синтетических данных (например, наборы _MNIST_ (http://yann.lecun.com/exdb/mnist/) или _notMNIST_).\n",
        "\n",
        "Ознакомьтесь с имеющимися работами по данной тематике: англоязычная статья ( http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf ), видео на _YouTube_ (https://www.youtube.com/watch?v=vGPI_JvLoN0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwZ5YedLSmq5",
        "colab_type": "text"
      },
      "source": [
        "Используем архитектуру _LeNet-5_ и обучим сеть сначала на данных из набора MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5VyFAn6oppw",
        "colab_type": "code",
        "outputId": "8cd7aeb0-26e5-4401-8fae-b61fa2a67ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "! pip install tensorflow-gpu --pre --quiet\n",
        "\n",
        "! pip show tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 516.1MB 30kB/s \n",
            "\u001b[?25hName: tensorflow-gpu\n",
            "Version: 2.2.0rc2\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: absl-py, gast, wrapt, grpcio, keras-preprocessing, tensorflow-estimator, tensorboard, termcolor, wheel, scipy, opt-einsum, astunparse, six, h5py, google-pasta, protobuf, numpy\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A6ova40mePh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxMOj2NcyUrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqe79JL0mGNh",
        "colab_type": "code",
        "outputId": "bb694360-3ce5-4f89-cf52-709a1961ff9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEaLeEAKy-sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val = tf.keras.utils.normalize(x_train, axis = 1), tf.keras.utils.normalize(x_val, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDy2wUQwyQFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val = x_train[..., np.newaxis], x_val[..., np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA-LEJ-DH85n",
        "colab_type": "code",
        "outputId": "5e52c93c-b4d0-4771-b898-00ff0398d36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train, y_val = to_categorical(y_train), to_categorical(y_val)\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW4-m2kcv1bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_DIM_0, IMAGE_DIM_1 = x_train.shape[1], x_train.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8FxR1mymxWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES_N = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfSn_LKOm6U_",
        "colab_type": "code",
        "outputId": "32cf9a11-c7e1-4262-ebd4-f9560da7874c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape, x_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGJQ6uXanJQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Flatten\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(6, kernel_size = (5, 5), strides = (1, 1), activation = 'tanh', padding = 'same',\n",
        "                   input_shape = (IMAGE_DIM_0, IMAGE_DIM_1, 1)))\n",
        "model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model.add(Conv2D(16, kernel_size = (5, 5), strides = (1, 1), activation = 'tanh', padding = 'valid'))\n",
        "model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120, activation = 'tanh'))\n",
        "model.add(Dense(84, activation = 'tanh'))\n",
        "model.add(Dense(CLASSES_N, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF5wW8VYnca7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'sparse_categorical_crossentropy' gave NAN loss\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiqd4HCfnezG",
        "colab_type": "code",
        "outputId": "86279e39-ad6c-4d19-bb48-ae0168b4900e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnv6sb5Tniww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS_N = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWfwaspGnsVK",
        "colab_type": "code",
        "outputId": "3c408dd6-e1ff-4530-a485-895b301c9cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), epochs = EPOCHS_N)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2580 - categorical_accuracy: 0.9216 - val_loss: 0.1337 - val_categorical_accuracy: 0.9576\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1109 - categorical_accuracy: 0.9656 - val_loss: 0.0900 - val_categorical_accuracy: 0.9706\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0757 - categorical_accuracy: 0.9764 - val_loss: 0.0701 - val_categorical_accuracy: 0.9779\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0604 - categorical_accuracy: 0.9809 - val_loss: 0.0776 - val_categorical_accuracy: 0.9754\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0465 - categorical_accuracy: 0.9851 - val_loss: 0.0577 - val_categorical_accuracy: 0.9814\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0396 - categorical_accuracy: 0.9873 - val_loss: 0.0642 - val_categorical_accuracy: 0.9819\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0318 - categorical_accuracy: 0.9897 - val_loss: 0.0559 - val_categorical_accuracy: 0.9821\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0266 - categorical_accuracy: 0.9916 - val_loss: 0.0580 - val_categorical_accuracy: 0.9817\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0239 - categorical_accuracy: 0.9922 - val_loss: 0.0616 - val_categorical_accuracy: 0.9813\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0201 - categorical_accuracy: 0.9934 - val_loss: 0.0579 - val_categorical_accuracy: 0.9831\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0176 - categorical_accuracy: 0.9942 - val_loss: 0.0605 - val_categorical_accuracy: 0.9824\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0155 - categorical_accuracy: 0.9951 - val_loss: 0.0524 - val_categorical_accuracy: 0.9849\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0156 - categorical_accuracy: 0.9946 - val_loss: 0.0528 - val_categorical_accuracy: 0.9844\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0124 - categorical_accuracy: 0.9955 - val_loss: 0.0578 - val_categorical_accuracy: 0.9840\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0122 - categorical_accuracy: 0.9960 - val_loss: 0.0636 - val_categorical_accuracy: 0.9838\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0105 - categorical_accuracy: 0.9966 - val_loss: 0.0634 - val_categorical_accuracy: 0.9845\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0108 - categorical_accuracy: 0.9963 - val_loss: 0.0657 - val_categorical_accuracy: 0.9836\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0117 - categorical_accuracy: 0.9958 - val_loss: 0.0644 - val_categorical_accuracy: 0.9841\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0097 - categorical_accuracy: 0.9967 - val_loss: 0.0644 - val_categorical_accuracy: 0.9840\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0079 - categorical_accuracy: 0.9973 - val_loss: 0.0610 - val_categorical_accuracy: 0.9844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7020198898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_YPL2eNS-IW",
        "colab_type": "text"
      },
      "source": [
        "Удалось достичь отличного результата &mdash; точность распознавания на валидационной выборке составила 98,4%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhEJUbH-b9RT",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "После уточнения модели на синтетических данных попробуйте обучить ее на реальных данных (набор _Google Street View_). Что изменилось в модели?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpjg0mUPPZzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DS_URL_FOLDER = 'http://ufldl.stanford.edu/housenumbers/'\n",
        "\n",
        "FIRST_DS_EXT = '.tar.gz'\n",
        "SECOND_DS_EXT = '_32x32.mat'\n",
        "\n",
        "TRAIN_DS_NAME = 'train'\n",
        "TEST_DS_NAME = 'test'\n",
        "EXTRA_DS_NAME = 'extra'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ1Au9pWQ1gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "def load_file(_url_folder, _name, _ext, _key, _local_ext = ''):\n",
        "\n",
        "    file_url_ = _url_folder + _name + _ext\n",
        "\n",
        "    local_file_name_ = _name + '_' + _key + _local_ext\n",
        "\n",
        "    urlretrieve(file_url_, local_file_name_)\n",
        "\n",
        "    return local_file_name_\n",
        "\n",
        "def tar_gz_to_dir(_url_folder, _name, _ext, _key):\n",
        "\n",
        "    local_file_name_ = load_file(_url_folder, _name, _ext, _key, _ext)\n",
        "\n",
        "    dir_name_ = _name + '_' + _key\n",
        "    \n",
        "    with tarfile.open(local_file_name_, 'r:gz') as tar_:\n",
        "        tar_.extractall(dir_name_)\n",
        "\n",
        "    os.remove(local_file_name_)\n",
        "\n",
        "    return dir_name_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMhgLBpdQ2M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_ds_train_dir = tar_gz_to_dir(DS_URL_FOLDER, TRAIN_DS_NAME, FIRST_DS_EXT, 'first')\n",
        "first_ds_test_dir = tar_gz_to_dir(DS_URL_FOLDER, TEST_DS_NAME, FIRST_DS_EXT, 'first')\n",
        "first_ds_extra_dir = tar_gz_to_dir(DS_URL_FOLDER, EXTRA_DS_NAME, FIRST_DS_EXT, 'first')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY9H9gOx_agn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "second_ds_train_file = load_file(DS_URL_FOLDER, TRAIN_DS_NAME, SECOND_DS_EXT, 'second')\n",
        "second_ds_test_file = load_file(DS_URL_FOLDER, TEST_DS_NAME, SECOND_DS_EXT, 'second')\n",
        "second_ds_extra_file = load_file(DS_URL_FOLDER, EXTRA_DS_NAME, SECOND_DS_EXT, 'second')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gIR7l4gLIha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! ls extra_first/extra"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRmvtvvHjWam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import io\n",
        "\n",
        "second_ds_train = io.loadmat(second_ds_train_file)\n",
        "second_ds_test = io.loadmat(second_ds_test_file)\n",
        "second_ds_extra = io.loadmat(second_ds_extra_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aZehuSyjtMa",
        "colab_type": "code",
        "outputId": "0279c0f0-cc56-499c-f0ca-a52d88e0d7eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "X_second_ds_train = np.moveaxis(second_ds_train['X'], -1, 0)\n",
        "X_second_ds_test = np.moveaxis(second_ds_test['X'], -1, 0)\n",
        "X_second_ds_extra = np.moveaxis(second_ds_extra['X'], -1, 0)\n",
        "\n",
        "y_second_ds_train = second_ds_train['y']\n",
        "y_second_ds_test = second_ds_test['y']\n",
        "y_second_ds_extra = second_ds_extra['y']\n",
        "\n",
        "print(X_second_ds_train.shape, y_second_ds_train.shape)\n",
        "print(X_second_ds_test.shape, y_second_ds_test.shape)\n",
        "print(X_second_ds_extra.shape, y_second_ds_extra.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(73257, 32, 32, 3) (73257, 1)\n",
            "(26032, 32, 32, 3) (26032, 1)\n",
            "(531131, 32, 32, 3) (531131, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rGezUtOltjt",
        "colab_type": "code",
        "outputId": "f064cb14-1343-4450-cb82-46fa33667a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X_second_ds_train[100])\n",
        "plt.imshow(X_second_ds_test[100])\n",
        "plt.imshow(X_second_ds_extra[100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f70023e9630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUuo9YEP3w0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_DIM_0_2, IMAGE_DIM_1_2, IMAGE_DIM_2_2 = X_second_ds_train.shape[-3], X_second_ds_train.shape[-2], X_second_ds_train.shape[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnfDnP9D5U_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_second_ds_train_cat = to_categorical(y_second_ds_train)\n",
        "y_second_ds_test_cat = to_categorical(y_second_ds_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSuoxju15AGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES_N_2 = y_second_ds_train_cat.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH96BC9-3s7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = tf.keras.Sequential()\n",
        "\n",
        "model_2.add(Conv2D(6, kernel_size = (5, 5), strides = (1, 1), activation = 'tanh', padding = 'same',\n",
        "                   input_shape = (IMAGE_DIM_0_2, IMAGE_DIM_1_2, IMAGE_DIM_2_2)))\n",
        "model_2.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model_2.add(Conv2D(16, kernel_size = (5, 5), strides = (1, 1), activation = 'tanh', padding = 'valid'))\n",
        "model_2.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(120, activation = 'tanh'))\n",
        "model_2.add(Dense(84, activation = 'tanh'))\n",
        "model_2.add(Dense(CLASSES_N_2, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxY6LEWR3q33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.compile(optimizer = 'adam',\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = ['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubm_QyIZ3qCV",
        "colab_type": "code",
        "outputId": "d15a86ea-b848-4ea7-d3b9-78c5c1726a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 6)         456       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average (None, 16, 16, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_7 (Average (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 120)               69240     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 11)                935       \n",
            "=================================================================\n",
            "Total params: 83,211\n",
            "Trainable params: 83,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAONS2Z92v8g",
        "colab_type": "code",
        "outputId": "4d0d5917-be55-4897-8927-68e70f24701d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "model_2.fit(x = X_second_ds_train, y = y_second_ds_train_cat,\n",
        "            validation_data = (X_second_ds_test, y_second_ds_test_cat),\n",
        "            epochs = EPOCHS_N)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 1.2603 - categorical_accuracy: 0.5877 - val_loss: 0.8378 - val_categorical_accuracy: 0.7328\n",
            "Epoch 2/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.7390 - categorical_accuracy: 0.7641 - val_loss: 0.7672 - val_categorical_accuracy: 0.7554\n",
            "Epoch 3/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.6408 - categorical_accuracy: 0.7952 - val_loss: 0.7343 - val_categorical_accuracy: 0.7676\n",
            "Epoch 4/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.5971 - categorical_accuracy: 0.8091 - val_loss: 0.7058 - val_categorical_accuracy: 0.7740\n",
            "Epoch 5/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.5655 - categorical_accuracy: 0.8197 - val_loss: 0.6665 - val_categorical_accuracy: 0.7923\n",
            "Epoch 6/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.5358 - categorical_accuracy: 0.8295 - val_loss: 0.6720 - val_categorical_accuracy: 0.7855\n",
            "Epoch 7/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.5174 - categorical_accuracy: 0.8361 - val_loss: 0.6566 - val_categorical_accuracy: 0.7959\n",
            "Epoch 8/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.5040 - categorical_accuracy: 0.8394 - val_loss: 0.6529 - val_categorical_accuracy: 0.7935\n",
            "Epoch 9/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.4870 - categorical_accuracy: 0.8447 - val_loss: 0.6480 - val_categorical_accuracy: 0.8001\n",
            "Epoch 10/20\n",
            "2290/2290 [==============================] - 8s 3ms/step - loss: 0.4750 - categorical_accuracy: 0.8486 - val_loss: 0.6462 - val_categorical_accuracy: 0.8032\n",
            "Epoch 11/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.4670 - categorical_accuracy: 0.8516 - val_loss: 0.6810 - val_categorical_accuracy: 0.7866\n",
            "Epoch 12/20\n",
            "2290/2290 [==============================] - 8s 4ms/step - loss: 0.4537 - categorical_accuracy: 0.8553 - val_loss: 0.6491 - val_categorical_accuracy: 0.7996\n",
            "Epoch 13/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.4534 - categorical_accuracy: 0.8555 - val_loss: 0.6035 - val_categorical_accuracy: 0.8130\n",
            "Epoch 14/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.4372 - categorical_accuracy: 0.8610 - val_loss: 0.6164 - val_categorical_accuracy: 0.8117\n",
            "Epoch 15/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.4273 - categorical_accuracy: 0.8638 - val_loss: 0.6125 - val_categorical_accuracy: 0.8099\n",
            "Epoch 16/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.4238 - categorical_accuracy: 0.8644 - val_loss: 0.6231 - val_categorical_accuracy: 0.8056\n",
            "Epoch 17/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.4054 - categorical_accuracy: 0.8708 - val_loss: 0.6689 - val_categorical_accuracy: 0.7969\n",
            "Epoch 18/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.4014 - categorical_accuracy: 0.8716 - val_loss: 0.6217 - val_categorical_accuracy: 0.8078\n",
            "Epoch 19/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.3941 - categorical_accuracy: 0.8748 - val_loss: 0.6191 - val_categorical_accuracy: 0.8110\n",
            "Epoch 20/20\n",
            "2290/2290 [==============================] - 7s 3ms/step - loss: 0.3900 - categorical_accuracy: 0.8759 - val_loss: 0.6034 - val_categorical_accuracy: 0.8143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fe803f240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLwTArXRTZY8",
        "colab_type": "text"
      },
      "source": [
        "Прежде всего, в модели изменилось то, что добавился ещё один класс &mdash; _нет цифры_. Это связано с тем, что в данные представляют собой снимки скользящего окна, в котором не всегда есть то, что мы хотим распознать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q-E6_NBTVOD",
        "colab_type": "text"
      },
      "source": [
        "Несмотря на это, результат также неплох &mdash; точность распознавания на валидационной выборке составила 81,4%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI_e3nVUcCXb",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3\n",
        "\n",
        "Сделайте множество снимков изображений номеров домов с помощью смартфона на ОС _Android_. Также можно использовать библиотеки _OpenCV_, _Simple CV_ или _Pygame_ для обработки изображений с общедоступных камер видеонаблюдения (например, https://www.earthcam.com/).\n",
        "\n",
        "В качестве примера использования библиотеки _TensorFlow_ на смартфоне можете воспользоваться демонстрационным приложением от _Google_ (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDRp62kQcQd8",
        "colab_type": "text"
      },
      "source": [
        "### Задание 4\n",
        "\n",
        "Реализуйте приложение для ОС _Android_, которое может распознавать цифры в номерах домов, используя разработанный ранее классификатор. Какова доля правильных классификаций?"
      ]
    }
  ]
}