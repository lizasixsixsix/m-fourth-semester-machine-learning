{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mo-2-6-0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_cfSTC_fExd",
        "colab_type": "text"
      },
      "source": [
        "# Лабораторная работа №6\n",
        "\n",
        "## Применение сверточных нейронных сетей (многоклассовая классификация)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj2xTHG6fYhe",
        "colab_type": "text"
      },
      "source": [
        "Набор данных для распознавания языка жестов, который состоит из изображений размерности 28x28 в оттенках серого (значение пикселя от 0 до 255).\n",
        "\n",
        "Каждое из изображений обозначает букву латинского алфавита, обозначенную с помощью жеста (изображения в наборе данных в оттенках серого).\n",
        "\n",
        "Обучающая выборка включает в себя 27,455 изображений, а контрольная выборка содержит 7172 изображения.\n",
        "\n",
        "Данные в виде _csv_-файлов можно скачать на сайте _Kaggle_: https://www.kaggle.com/datamunge/sign-language-mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R2bvokTfwuG",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Загрузите данные. Разделите исходный набор данных на обучающую и валидационную выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSU2rJJGrn5s",
        "colab_type": "code",
        "outputId": "50be9f38-6f4c-49a8-81aa-ef106af64b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw--OkDXry4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = '/content/drive/My Drive/Colab Files/mo-2'\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append(BASE_DIR)\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLSt5UKjr2q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_ARCHIVE_NAME = 'sign-language-mnist.zip'\n",
        "\n",
        "LOCAL_DIR_NAME = 'sign-language'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRDKuhNDsHcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(os.path.join(BASE_DIR, DATA_ARCHIVE_NAME), 'r') as zip_:\n",
        "    zip_.extractall(path = os.path.join(LOCAL_DIR_NAME, 'train'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eaDS5TrsMIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_FILE_PATH = 'sign-language/train/sign_mnist_train.csv'\n",
        "TEST_FILE_PATH = 'sign-language/train/sign_mnist_test.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xZdjccQssbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_FILE_PATH)\n",
        "test_df = pd.read_csv(TEST_FILE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIs-JqDptwi7",
        "colab_type": "code",
        "outputId": "144d824c-fdbe-47e2-8c4a-853b03a73e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27455, 785), (7172, 785))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WTptMAe7IFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_DIM = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxYJPtuG7jpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def row_to_label(_row):\n",
        "    return _row[0]\n",
        "\n",
        "def row_to_one_image(_row):\n",
        "    return _row[1:].values.reshape((IMAGE_DIM, IMAGE_DIM, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Fmd0L49EEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_images_and_labels(_dataframe):\n",
        "\n",
        "    llll = _dataframe.apply(lambda row: row_to_label(row), axis = 1)\n",
        "    mmmm = _dataframe.apply(lambda row: row_to_one_image(row), axis = 1)\n",
        "\n",
        "    data_dict_ = { 'label': llll, 'image': mmmm }\n",
        "\n",
        "    reshaped_ = pd.DataFrame(data_dict_, columns = ['label', 'image'])\n",
        "\n",
        "    return reshaped_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PeWh5EJM6pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_reshaped = to_images_and_labels(train_df)\n",
        "test_df_reshaped = to_images_and_labels(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0p2LpcBf02u",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "Реализуйте глубокую нейронную сеть со сверточными слоями. Какое качество классификации получено? Какая архитектура сети была использована?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlORE3O0FQQ8",
        "colab_type": "text"
      },
      "source": [
        "Возьмём _LeNet-5_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxG1n5fUJP9d",
        "colab_type": "code",
        "outputId": "23fdc212-e2b0-4aac-8072-e905beb02f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "! pip install tensorflow-gpu --pre --quiet\n",
        "\n",
        "! pip show tensorflow-gpu"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow-gpu\n",
            "Version: 2.2.0rc3\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: google-pasta, h5py, grpcio, opt-einsum, scipy, protobuf, wrapt, six, absl-py, tensorboard, wheel, gast, termcolor, numpy, tensorflow-estimator, keras-preprocessing, astunparse\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Ium3RsJTM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wDnBN8RACua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "X_train = tf.keras.utils.normalize(np.asarray(list(train_df_reshaped['image'])), axis = 1)\n",
        "X_test = tf.keras.utils.normalize(np.asarray(list(test_df_reshaped['image'])), axis = 1)\n",
        "\n",
        "y_train = to_categorical(train_df_reshaped['label'].astype('category').cat.codes.astype('int32'))\n",
        "y_test = to_categorical(test_df_reshaped['label'].astype('category').cat.codes.astype('int32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOG3bi2slMco",
        "colab_type": "code",
        "outputId": "389ecd24-16da-43cb-d37d-21b49315b80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27455, 28, 28, 1), (27455, 24), (7172, 28, 28, 1), (7172, 24))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8mEQ38cA9Fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES_N = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0cFJ4s5FN2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Flatten\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(6, kernel_size = (5, 5), strides = (1, 1), activation = 'tanh', padding = 'same',\n",
        "                   input_shape = (IMAGE_DIM, IMAGE_DIM, 1)))\n",
        "model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model.add(Conv2D(16, kernel_size = (5, 5), strides = (1, 1), activation = 'tanh', padding = 'valid'))\n",
        "model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120, activation = 'tanh'))\n",
        "model.add(Dense(84, activation = 'tanh'))\n",
        "model.add(Dense(CLASSES_N, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo7TE0JOGabq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f85ff3c9-bc84-41c5-c92f-4445ee420ade",
        "id": "SdowxeAVaqmz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 24)                2040      \n",
            "=================================================================\n",
            "Total params: 62,896\n",
            "Trainable params: 62,896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYpxqvQMGiy6",
        "colab_type": "code",
        "outputId": "52cb3769-8a13-4329-e816-20a942d39ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "model.fit(x = X_train, y = y_train, epochs = 20, validation_split = 0.15)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 1.2958 - categorical_accuracy: 0.6188 - val_loss: 0.5418 - val_categorical_accuracy: 0.8657\n",
            "Epoch 2/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.3189 - categorical_accuracy: 0.9325 - val_loss: 0.1453 - val_categorical_accuracy: 0.9830\n",
            "Epoch 3/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0807 - categorical_accuracy: 0.9949 - val_loss: 0.0389 - val_categorical_accuracy: 0.9998\n",
            "Epoch 4/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0262 - categorical_accuracy: 0.9997 - val_loss: 0.0160 - val_categorical_accuracy: 0.9998\n",
            "Epoch 5/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0111 - categorical_accuracy: 1.0000 - val_loss: 0.0099 - val_categorical_accuracy: 0.9998\n",
            "Epoch 6/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0058 - categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0033 - categorical_accuracy: 1.0000 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0145 - categorical_accuracy: 0.9964 - val_loss: 0.0043 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 9.1311e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 7.3560e-04 - categorical_accuracy: 1.0000 - val_loss: 6.3469e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 5.1847e-04 - categorical_accuracy: 1.0000 - val_loss: 4.7602e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 3.6735e-04 - categorical_accuracy: 1.0000 - val_loss: 3.2560e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 2.6058e-04 - categorical_accuracy: 1.0000 - val_loss: 2.3029e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 1.8485e-04 - categorical_accuracy: 1.0000 - val_loss: 1.6227e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 1.2857e-04 - categorical_accuracy: 1.0000 - val_loss: 1.1164e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 8.9278e-05 - categorical_accuracy: 1.0000 - val_loss: 7.7735e-05 - val_categorical_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 6.2117e-05 - categorical_accuracy: 1.0000 - val_loss: 5.2588e-05 - val_categorical_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 4.2049e-05 - categorical_accuracy: 1.0000 - val_loss: 3.7133e-05 - val_categorical_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 2.8740e-05 - categorical_accuracy: 1.0000 - val_loss: 2.5821e-05 - val_categorical_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd5b1433ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLqAfoeSlVM9",
        "colab_type": "code",
        "outputId": "3914f37f-8bae-47a4-db5b-bf5fb6885da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "results = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test loss, test accuracy:', results)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 0s 2ms/step - loss: 0.8982 - categorical_accuracy: 0.8256\n",
            "Test loss, test accuracy: [0.8982465267181396, 0.8255716562271118]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0IKq9rnDL0v",
        "colab_type": "text"
      },
      "source": [
        "За 20 эпох удалось достичь точности 82% на тестовой выборке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDd07Vzwf4fM",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3\n",
        "\n",
        "Примените дополнение данных (_data augmentation_). Как это повлияло на качество классификатора?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06eplvBAbaqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_image(image):\n",
        "\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize_with_crop_or_pad(image, IMAGE_DIM + 6, IMAGE_DIM + 6)\n",
        "  image = tf.image.random_crop(image, size = [IMAGE_DIM, IMAGE_DIM, 1])\n",
        "\n",
        "  return image.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS1YVgFJbVKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "323cb758-f83a-47d9-d210-a7bf91af7e7f"
      },
      "source": [
        "X_train_augmented = np.zeros_like(X_train)\n",
        "\n",
        "for i, img in enumerate(X_train):\n",
        "\n",
        "    X_train_augmented[i] = augment_image(img)\n",
        "\n",
        "X_train_augmented.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcXa5asIdtFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_augmented = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zphHpK8CMFbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "7d5e6d38-37f7-4e26-b766-382cca9f7acb"
      },
      "source": [
        "model.fit(x = X_train_augmented, y = y_train_augmented, epochs = 20, validation_split = 0.15)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 1.5178 - categorical_accuracy: 0.5917 - val_loss: 0.9175 - val_categorical_accuracy: 0.7242\n",
            "Epoch 2/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.7474 - categorical_accuracy: 0.7681 - val_loss: 0.6898 - val_categorical_accuracy: 0.7917\n",
            "Epoch 3/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.5514 - categorical_accuracy: 0.8275 - val_loss: 0.6034 - val_categorical_accuracy: 0.8126\n",
            "Epoch 4/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.4323 - categorical_accuracy: 0.8700 - val_loss: 0.5026 - val_categorical_accuracy: 0.8441\n",
            "Epoch 5/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.3474 - categorical_accuracy: 0.8959 - val_loss: 0.4365 - val_categorical_accuracy: 0.8667\n",
            "Epoch 6/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.2858 - categorical_accuracy: 0.9161 - val_loss: 0.3873 - val_categorical_accuracy: 0.8823\n",
            "Epoch 7/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.2393 - categorical_accuracy: 0.9299 - val_loss: 0.3671 - val_categorical_accuracy: 0.8866\n",
            "Epoch 8/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.1912 - categorical_accuracy: 0.9464 - val_loss: 0.3188 - val_categorical_accuracy: 0.9022\n",
            "Epoch 9/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.1655 - categorical_accuracy: 0.9549 - val_loss: 0.3211 - val_categorical_accuracy: 0.9000\n",
            "Epoch 10/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.1389 - categorical_accuracy: 0.9637 - val_loss: 0.2843 - val_categorical_accuracy: 0.9153\n",
            "Epoch 11/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.1186 - categorical_accuracy: 0.9684 - val_loss: 0.2725 - val_categorical_accuracy: 0.9145\n",
            "Epoch 12/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0984 - categorical_accuracy: 0.9751 - val_loss: 0.2554 - val_categorical_accuracy: 0.9192\n",
            "Epoch 13/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0848 - categorical_accuracy: 0.9790 - val_loss: 0.2307 - val_categorical_accuracy: 0.9272\n",
            "Epoch 14/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0729 - categorical_accuracy: 0.9834 - val_loss: 0.2121 - val_categorical_accuracy: 0.9323\n",
            "Epoch 15/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0724 - categorical_accuracy: 0.9811 - val_loss: 0.2220 - val_categorical_accuracy: 0.9272\n",
            "Epoch 16/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0627 - categorical_accuracy: 0.9843 - val_loss: 0.2005 - val_categorical_accuracy: 0.9398\n",
            "Epoch 17/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0499 - categorical_accuracy: 0.9891 - val_loss: 0.2056 - val_categorical_accuracy: 0.9378\n",
            "Epoch 18/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0469 - categorical_accuracy: 0.9899 - val_loss: 0.2001 - val_categorical_accuracy: 0.9366\n",
            "Epoch 19/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0539 - categorical_accuracy: 0.9859 - val_loss: 0.2164 - val_categorical_accuracy: 0.9366\n",
            "Epoch 20/20\n",
            "730/730 [==============================] - 2s 3ms/step - loss: 0.0478 - categorical_accuracy: 0.9872 - val_loss: 0.1852 - val_categorical_accuracy: 0.9434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd58874f5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UriSZMNWeFFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "400f5410-a2ab-4652-ab80-2566a81434dd"
      },
      "source": [
        "results_2 = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test loss, test accuracy:', results_2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 0s 2ms/step - loss: 0.2964 - categorical_accuracy: 0.9140\n",
            "Test loss, test accuracy: [0.296428382396698, 0.9139710068702698]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QA8Rva5eJ63",
        "colab_type": "text"
      },
      "source": [
        "После того, как сеть обучилась на тех же данных, к которым был применён _data augmentation_, точность предсказания на тестовой выборке увеличилась до 91%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nPvDhWtf9EW",
        "colab_type": "text"
      },
      "source": [
        "### Задание 4\n",
        "\n",
        "Поэкспериментируйте с готовыми нейронными сетями (например, _AlexNet_, _VGG16_, _Inception_ и т.п.), применив передаточное обучение. Как это повлияло на качество классификатора? Можно ли было обойтись без него?\n",
        "\n",
        "Какой максимальный результат удалось получить на контрольной выборке?"
      ]
    }
  ]
}